# Data Engineer Learning Path - Python & SQL

A comprehensive learning path for aspiring data engineers, covering essential Python programming and SQL database skills needed for modern data engineering roles.

## 📚 Table of Contents

- [Overview](#overview)
- [Learning Path](#learning-path)
- [Prerequisites](#prerequisites)
- [Repository Structure](#repository-structure)
- [How to Use This Repository](#how-to-use-this-repository)
- [Resources](#resources)
- [Contributing](#contributing)

## 🎯 Overview

This repository provides a structured learning path for data engineers, focusing on:
- **Python Programming**: From basics to advanced data manipulation
- **SQL Databases**: Query writing, optimization, and database design
- **Data Engineering Concepts**: ETL/ELT, data pipelines, and data warehousing
- **Practical Projects**: Hands-on exercises and real-world scenarios

## 🛣️ Learning Path

### Phase 1: Python Fundamentals (2-4 weeks)
- [ ] Python basics: variables, data types, control structures
- [ ] Functions and modules
- [ ] Object-oriented programming
- [ ] Error handling and debugging
- [ ] File I/O operations

### Phase 2: Python for Data Engineering (4-6 weeks)
- [ ] Data structures: lists, dictionaries, sets, tuples
- [ ] Working with libraries: NumPy, Pandas
- [ ] Data manipulation and transformation
- [ ] API interactions and web scraping
- [ ] Working with CSV, JSON, and XML files

### Phase 3: SQL Fundamentals (3-4 weeks)
- [ ] Basic SQL queries: SELECT, WHERE, ORDER BY
- [ ] Joins: INNER, LEFT, RIGHT, FULL OUTER
- [ ] Aggregate functions and GROUP BY
- [ ] Subqueries and CTEs (Common Table Expressions)
- [ ] Window functions

### Phase 4: Advanced SQL (3-4 weeks)
- [ ] Database design and normalization
- [ ] Indexes and query optimization
- [ ] Stored procedures and functions
- [ ] Transactions and ACID properties
- [ ] Working with different SQL databases (PostgreSQL, MySQL, SQLite)

### Phase 5: Data Engineering Concepts (4-6 weeks)
- [ ] ETL vs ELT processes
- [ ] Data pipelines and orchestration
- [ ] Data warehousing concepts
- [ ] Data quality and validation
- [ ] Version control with Git

### Phase 6: Advanced Topics (6-8 weeks)
- [ ] Working with big data tools (introduction to Spark)
- [ ] Cloud platforms (AWS, GCP, Azure basics)
- [ ] Data streaming concepts
- [ ] Docker and containerization
- [ ] Testing and CI/CD for data pipelines

### Phase 7: Practical Projects
- [ ] Build an ETL pipeline
- [ ] Create a data warehouse
- [ ] Implement data quality checks
- [ ] Build a dashboard with real-time data

## 📋 Prerequisites

- Basic computer literacy
- Understanding of basic programming concepts (helpful but not required)
- Willingness to learn and practice regularly
- A computer with internet access

### Required Software
- Python 3.8 or higher
- A SQL database (PostgreSQL recommended, SQLite for beginners)
- Git for version control
- A code editor (VS Code, PyCharm, or similar)

## 📁 Repository Structure

```
.
├── 01-python-fundamentals/       # Python basics and fundamentals
│   ├── lessons/                  # Theory and explanations
│   ├── examples/                 # Code examples
│   └── exercises/                # Practice exercises
│
├── 02-python-data-engineering/   # Python for data tasks
│   ├── lessons/
│   ├── examples/
│   └── exercises/
│
├── 03-sql-fundamentals/          # Basic SQL concepts
│   ├── lessons/
│   ├── queries/                  # SQL query examples
│   └── exercises/
│
├── 04-advanced-sql/              # Advanced SQL topics
│   ├── lessons/
│   ├── queries/
│   └── exercises/
│
├── 05-data-engineering/          # Data engineering concepts
│   ├── lessons/
│   ├── projects/
│   └── exercises/
│
├── 06-advanced-topics/           # Advanced data engineering
│   ├── lessons/
│   ├── projects/
│   └── exercises/
│
├── 07-projects/                  # Capstone projects
│   ├── etl-pipeline/
│   ├── data-warehouse/
│   └── real-time-dashboard/
│
└── resources/                    # Additional resources
    ├── books.md
    ├── courses.md
    └── tools.md
```

## 🚀 How to Use This Repository

1. **Clone the repository**
   ```bash
   git clone https://github.com/fabianomalves/data_engineer_learning_python_sql_path.git
   cd data_engineer_learning_python_sql_path
   ```

2. **Follow the learning path sequentially**
   - Start with Phase 1 and progress through each phase
   - Complete exercises before moving to the next section
   - Work on projects to apply your knowledge

3. **Practice regularly**
   - Code daily, even if just for 30 minutes
   - Review concepts regularly
   - Build your own projects alongside the provided ones

4. **Track your progress**
   - Check off completed topics in the learning path
   - Keep a learning journal
   - Share your progress and projects

## 📖 Resources

### Books
- "Python for Data Analysis" by Wes McKinney
- "SQL Performance Explained" by Markus Winand
- "Designing Data-Intensive Applications" by Martin Kleppmann

### Online Platforms
- DataCamp
- Coursera
- LeetCode (for SQL practice)
- HackerRank

### Documentation
- [Python Official Documentation](https://docs.python.org/3/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

## 🤝 Contributing

Contributions are welcome! If you'd like to contribute:

1. Fork the repository
2. Create a new branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Commit your changes (`git commit -am 'Add new feature'`)
5. Push to the branch (`git push origin feature/improvement`)
6. Create a Pull Request

## 📝 License

This project is open source and available under the MIT License.

## ⭐ Acknowledgments

This learning path is designed to help aspiring data engineers build a strong foundation in Python and SQL, the two most essential skills for modern data engineering roles.

---

**Happy Learning! 🚀**

For questions or discussions, please open an issue in this repository.
